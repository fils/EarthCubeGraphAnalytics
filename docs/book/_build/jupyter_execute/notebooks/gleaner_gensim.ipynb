{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta4UtFPOmhEN"
   },
   "source": [
    "# Gensim\n",
    "\n",
    "This is an exploration of Gensim as a potential to create the \"node set\", V,  results from a semantic search.  That would wouild be fed into a graph database and used to start the path searches and or analysis to create the desired results set for an interface.\n",
    "\n",
    "This V_semsearch might be intersected with a V_spatial and or others to form a node set for the graph.  This is essentially a search \"preprocessor\". Another potential set might be V_text that usses more calssical full text index approaches.  \n",
    "\n",
    "## References\n",
    "\n",
    "* https://github.com/topics/document-similarity\n",
    "* https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9Re_OoSDlSVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: dask[dataframe]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\r\n",
      "\r\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\r\n",
      "\r\n",
      "boto3 1.17.46 requires botocore<1.21.0,>=1.20.46, but you'll have botocore 1.19.52 which is incompatible.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\r\n",
      "\r\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\r\n",
      "\r\n",
      "aiobotocore 1.2.2 requires botocore<1.19.53,>=1.19.52, but you'll have botocore 1.20.71 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip install -q --upgrade gensim\n",
    "!pip install -q  dask[dataframe] --upgrade\n",
    "!pip install -q s3fs\n",
    "!pip install -q boto3\n",
    "!pip install -q python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqyuQ2Ofl-fr",
    "outputId": "fc4a1427-c486-4664-c5c1-00d14c5fddf6"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import dask, boto3\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27XGS8Mk4Bm_"
   },
   "source": [
    "## Gleaner Data\n",
    "\n",
    "First lets load up some of the data Gleaner has collected.  This is just simple data graph objects and not any graphs or other processed products from Gleaner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_tZgszLR4YSm"
   },
   "outputs": [],
   "source": [
    "# Set up our S3FileSystem object\n",
    "import s3fs \n",
    "oss = s3fs.S3FileSystem(\n",
    "      anon=True,\n",
    "      client_kwargs = {\"endpoint_url\":\"https://oss.geodex.org\"}\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcSMBWuD6DWU"
   },
   "source": [
    "## Further examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jta0pzeOKbG0"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "@dask.delayed()\n",
    "def read_a_file(fn):\n",
    "    # or preferably open in text mode and json.load from the file\n",
    "    with oss.open(fn, 'rb') as f:\n",
    "        #return json.loads(f.read().replace('\\n',' '))\n",
    "        return json.loads(f.read().decode(\"utf-8\", \"ignore\").replace('\\n',' '))\n",
    "\n",
    "filenames = oss.ls('gleaner/summoned/opentopo')\n",
    "output = [read_a_file(f) for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Uwjzh7PmK5Z9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc has bad encoding\n"
     ]
    }
   ],
   "source": [
    "gldf = pd.DataFrame(columns=['name', 'url', \"keywords\", \"description\"])\n",
    "\n",
    "for doc in range(len(output)):\n",
    "#for doc in range(10):\n",
    "  try:\n",
    "    jld = output[doc].compute()\n",
    "  except:\n",
    "    print(\"Doc has bad encoding\")\n",
    "\n",
    "  # TODO  Really need to flatten and or frame this\n",
    "\n",
    "  desc = jld[\"description\"]\n",
    "  kws = jld[\"keywords\"]\n",
    "  name = jld[\"name\"]\n",
    "  url = jld[\"url\"]  \n",
    "  gldf = gldf.append({'name':name, 'url':url, 'keywords':kws, 'description': desc}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YBhd00_aLIF",
    "outputId": "4f91e502-f103-42ab-9029-53be286c717b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 654 entries, 0 to 653\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   name         654 non-null    object\n",
      " 1   url          654 non-null    object\n",
      " 2   keywords     654 non-null    object\n",
      " 3   description  654 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 20.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# gldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pub17I6ZlaxZ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# document = \"Human machine interface for lab abc computer applications\"\n",
    "\n",
    "# text_corpus = [\n",
    "#     \"Human machine interface for lab abc computer applications\",\n",
    "#     \"A survey of user opinion of computer system response time\",\n",
    "#     \"The EPS user interface management system\",\n",
    "#     \"System and human system engineering testing of EPS\",\n",
    "#     \"Relation of user perceived response time to error measurement\",\n",
    "#     \"The generation of random binary unordered trees\",\n",
    "#     \"The intersection graph of paths in trees\",\n",
    "#     \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#     \"Graph minors A survey\",\n",
    "# ]\n",
    "\n",
    "text_corpus = []\n",
    "\n",
    "# for i in range(len(gldf)):\n",
    "#   text_corpus += gldf.at[i,'description']\n",
    "\n",
    "for i in range(len(gldf)):\n",
    "# for i in range(10):\n",
    "  d = gldf.at[i,'description']\n",
    "  # d.replace('(', '').replace(')', '').replace('\\\"', '')\n",
    "  dp = re.sub(r'[^A-Za-z0-9 ]+', '', str(d))\n",
    "  text_corpus.append(str(dp))\n",
    "\n",
    "  # if not \"http\" in d:\n",
    "  #   if not \"(\" in d:\n",
    "  #     if not \"<\" in d:\n",
    "  #       text_corpus.append(str(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4oJRv74znBp",
    "outputId": "b7cee153-495d-4442-b739-1c1c8eff7043"
   },
   "outputs": [],
   "source": [
    "# for x in range(len(text_corpus)):\n",
    "#   print(text_corpus[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "T3sDhif_lyw5"
   },
   "outputs": [],
   "source": [
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "# pprint.pprint(processed_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1PdVoSrl7Wb",
    "outputId": "3d73fb02-def1-4aa3-fff9-5c5ba9a759bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(4443 unique tokens: ['2010', '2016066280', 'aa', 'affonso', 'airborne']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DkdRut5bmOe5"
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TThHhFQsmyTI",
    "outputId": "5f9ef037-1a46-4dcb-9156-9a86c66ebc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1304, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Side demo\n",
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0pZ9gHQDnFem"
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "# pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jhmi90LfnTAE",
    "outputId": "26c46932-5a17-4bf9-dc62-03365561c461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(212, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# transform the \"system minors\" string\n",
    "words = \"system minors\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "hkVlojHUno0Z",
    "outputId": "64c19555-807b-4106-ff39-bc09e28896f9"
   },
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "X8QpjVHQn6kO",
    "outputId": "cd2bd980-184c-4c45-ed0c-1b310298a1e9"
   },
   "outputs": [],
   "source": [
    "query_document = 'Airborne Laser Mapping'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "nxr3o091n9Y6",
    "outputId": "08fc1396-5cc3-4d4c-c520-3f4da14addb0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7663932f4991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdocument_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sims' is not defined"
     ]
    }
   ],
   "source": [
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMd-RIxIzDEC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gensim.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}