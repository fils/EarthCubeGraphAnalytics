
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Processing digital elevation data for deep learning models using Keras Spatial &#8212; EarthCube GeoCODES Exploration</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Intake / Pangeo Catalog: Making It Easier To Consume Earth’s Climate and Weather Data" href="../ec20_banihirwe_etal/intake-pangeo-catalog.html" />
    <link rel="prev" title="EC2020 examples" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/logo.webp" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">EarthCube GeoCODES Exploration</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Exploring GeoCODES
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content.html">
   Content in Jupyter Book
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../markdown.html">
     Markdown Files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../notebooks.html">
     Content with notebooks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../analysis.html">
     Data Unit Testing, ranking, clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../partfile.html">
   Notebooks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../notebooks/gleaner_clustering.html">
     SciKit K-means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../notebooks/gleaner_gensim.html">
     Gensim
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../notebooks/gleaner_txtai.html">
     Gleaner &amp; txtai
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../notebooks/ECO_GraphAnalytics.html">
     EarthCube Graph Analytics Exploration
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   EC2020 examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Processing digital elevation data for deep learning models using Keras Spatial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ec20_banihirwe_etal/intake-pangeo-catalog.html">
     Intake / Pangeo Catalog: Making It Easier To Consume Earth’s Climate and Weather Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ec20_busecke_etal/busecke_abernathey_earthcube2020.html">
     CMIP6 without the interpolation: Grid-native analysis with Pangeo in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ec20_hamman_etal/2020ECAHM-scikit-downscale.html">
     Scikit-downscale: an open source Python package for scalable climate downscaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ec20_havlin_etal/notebook/ec20_havlin_etal.html">
     3D volume rendering of geophysical data using the yt platform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ec20_peckham_etal/BALTO_GUI_v2.html">
     BALTO Graphical User Interface (A Prototype)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ec2020/ec20_soliman_etal/ks-preprocess-dem.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/fils/EarthCubeGraphAnalytics"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/fils/EarthCubeGraphAnalytics/issues/new?title=Issue%20on%20page%20%2Fec2020/ec20_soliman_etal/ks-preprocess-dem.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/fils/EarthCubeGraphAnalytics/master?urlpath=lab/tree/book/ec2020/ec20_soliman_etal/ks-preprocess-dem.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="your-hub-url/hub/user-redirect/git-pull?repo=https://github.com/fils/EarthCubeGraphAnalytics&urlpath=lab/tree/EarthCubeGraphAnalytics/book/ec2020/ec20_soliman_etal/ks-preprocess-dem.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/fils/EarthCubeGraphAnalytics/blob/master/book/ec2020/ec20_soliman_etal/ks-preprocess-dem.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aiman-soliman-and-jeffrey-terstriep">
   Aiman Soliman  and Jeffrey Terstriep
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-avoid-ad-hoc-preprocessing-with-keras-spatial">
   1. How to avoid ad hoc preprocessing with Keras Spatial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-keras-spatial">
   2. What is Keras Spatial?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spatial-data-generator">
     2.1 Spatial Data Generator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sample-definition-utilities">
     2.2 Sample Definition Utilities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sample-iterator">
     2.3 Sample Iterator
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-practical-example-preprocessing-digital-elevation-models-dem">
   3. A Practical Example: Preprocessing Digital Elevation Models (DEM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#managing-sample-space">
     3.1 Managing sample space
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#selecting-samples-within-an-area-of-interest">
       Selecting samples within an area of interest
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#calculating-attributes-for-each-sample">
       Calculating attributes for each sample
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-global-statistics">
     3.2 Estimating global statistics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sample-normalization-using-a-callback-function">
     3.3 Sample normalization using a callback function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feeding-data-directly-to-train-a-deep-learning-model">
     3.4 Feeding data directly to train a deep learning model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   4. Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgment">
   Acknowledgment
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="processing-digital-elevation-data-for-deep-learning-models-using-keras-spatial">
<h1>Processing digital elevation data for deep learning models using Keras Spatial<a class="headerlink" href="#processing-digital-elevation-data-for-deep-learning-models-using-keras-spatial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="aiman-soliman-and-jeffrey-terstriep">
<h2>Aiman Soliman  and Jeffrey Terstriep<a class="headerlink" href="#aiman-soliman-and-jeffrey-terstriep" title="Permalink to this headline">¶</a></h2>
<p>National Center for Supercomputing Applications (NCSA)</p>
<p>University of Illinois at Urbana-Champaign, Urbana, Illinois</p>
</div>
<div class="section" id="how-to-avoid-ad-hoc-preprocessing-with-keras-spatial">
<h2>1. How to avoid ad hoc preprocessing with Keras Spatial<a class="headerlink" href="#how-to-avoid-ad-hoc-preprocessing-with-keras-spatial" title="Permalink to this headline">¶</a></h2>
<p>There are endless possibilities for developing deep learning applications to extract geospatial insights from large remote sensing archives such as <a class="reference external" href="https://earthdata.nasa.gov/eosdis/daacs/lpdaac">NASA LP DAAC</a> and <a class="reference external" href="https://nsidc.org/">NSIDC DAAC</a>. However, if you have tried to develop your GeoAI application, you must have already stumbled upon the hurdle of getting remote sensing data ready for your deep learning model. Unlike regular images, remote sensing data includes important information about their location, map projection, and coordinate system. Further, rasters tend to be stored in a single file much larger than a single training sample. A common solution around this problem is to ‘chop’ the large remote sensing image in many equal-sized samples. This ad hoc process becomes even more tedious if you would like to repeat the experiment with your GeoAI model as each change of the model input dimensions (i.e., width and height) would require repeating the entire preprocessing steps and duplicating your data.</p>
<p>In this notebook, you will learn how to avoid these problems by using Keras Spatial, a new python library for preprocessing geospatial data. This library will help you feed your remote sensing data as batches with predefined dimensions, without worrying too much about preprocessing your data in advance. The key point here is that Keras Spatial will handle the projection and the spatial resolution of your remote sensing data and let you specify your input dimensions as if you are handling a regular image.</p>
</div>
<div class="section" id="what-is-keras-spatial">
<h2>2. What is Keras Spatial?<a class="headerlink" href="#what-is-keras-spatial" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/ncsa/keras-spatial">Keras Spatial</a> is a python package designed to be part of Keras’ preprocessing library. It provides capabilities to generate samples and extracting tensor data derived on-the-fly from a raster data source. The most significant design principle for Keras Spatial is the separation of the sample boundary and array size passed to the DL model. The researcher can define a coordinate reference system and sample size in spatial coordinates that are most appropriate to the problem being solved. Following, multiple raster sources can be easily merged together, while re-projection and re-sampling will be done automatically to match the dimensions of the model’s input layer.</p>
<p>Following we will discuss with examples the three main components of Keras Spatial: (1) a SpatialDataGenerator (SDG) class that handles access to raster data, (2) Sample definition utilities to aid in the definition of sample boundaries, and (3) Sample Iterator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">rasterio.plot</span> <span class="kn">import</span> <span class="n">show</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="spatial-data-generator">
<h3>2.1 Spatial Data Generator<a class="headerlink" href="#spatial-data-generator" title="Permalink to this headline">¶</a></h3>
<p>If you are familiar with the deep learning framework <a class="reference external" href="https://keras.io/">Keras</a>, then the SpatialDataGenerator (SDG) resembles the standard <a class="reference external" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html">Keras ImageDataGenerator class</a>. The main difference is that SDG extracts sample data from raster files on-the-fly. This approach is more convenient for remote sensing applications, where the dimensions of an input raster file are not equal to the dimensions of a single sample and it may be desirable to extract hundreds or thousands of samples from a single raster. SDG also understands coordinate reference systems and transparently handles reprojection when required.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras_spatial</span> <span class="kn">import</span> <span class="n">SpatialDataGenerator</span>

<span class="n">raster_dem</span> <span class="o">=</span> <span class="s1">&#39;./data/raster.tiff&#39;</span> 
<span class="n">sdg</span> <span class="o">=</span> <span class="n">SpatialDataGenerator</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">raster_dem</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sdg</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">meta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;driver&#39;: &#39;GTiff&#39;, &#39;dtype&#39;: &#39;float32&#39;, &#39;nodata&#39;: -9999.0, &#39;width&#39;: 2000, &#39;height&#39;: 2000, &#39;count&#39;: 1, &#39;crs&#39;: CRS.from_epsg(3443), &#39;transform&#39;: Affine(48.96, 0.0, 801795.0,
       0.0, -42.5675, 1460734.99)}
</pre></div>
</div>
</div>
</div>
<p>As can be seen in the final print statement above, the RasterIO src instance is available from the SDG and is useful when inspecting the source raster. The SDG class wraps the RasterIO file class and provides many of the same attributes and methods. In general, the SDG attributes and methods should be preferred as the RasterIO src may be opened and closed automatically during program execution.</p>
<p>Using default parameters, the SDG will return samples in the same coordinate reference system as the source raster. An alternative system can be chosen using the <em>crs</em> parameter or <em>crs</em> attribute. Similarly <em>indexes</em> can be used to specify one or more bands from the source raster. The SDG also supports standard interpolation methods (nearest neighbor, bilinear, cubic, etc) as provided by <a class="reference external" href="http://www.gdal.org">the GDAL library</a> and the <a class="reference external" href="https://github.com/mapbox/rasterio">Rasterio package</a>. Resampling becomes significant when transforming from raster pixel size to sample size as will be shown in more detail later.</p>
</div>
<div class="section" id="sample-definition-utilities">
<h3>2.2 Sample Definition Utilities<a class="headerlink" href="#sample-definition-utilities" title="Permalink to this headline">¶</a></h3>
<p>In addition to the source raster data, a GeoAI model will require a set of sample boundaries. Samples can be any vector source containing polygons that can be read into a GeoPandas GeoDataframe. If pre-defined boundaries are not available, the Keras Spatial grid module provides two functions for generating GeoDataFrames that define the samples, regular_grid, and random_grid. Both require the spatial extent of the study area, the sample size in the source coordinate units, and the coordinate reference system (CRS). The regular_grid may also include a percentage overlap that increases the number of samples available to model.</p>
<p>The SDG class includes convenience methods that provide a shortcut in accessing these functions where the spatial extent and CRS are determined directly from the raster source. By default, the sample width and height are specified in the native coordinate system units (in this case, feet). Alternatively, samples can be specified in pixels by using the <em>units=’pixels’</em> parameter.</p>
<p>Regardless of the approach used, the sample boundaries will be defined in spatial coordinates and are <strong>unrelated</strong> to the final array size that will be passed to the model. The sample size should be based on the geometry or physical attributes of the feature being studied. For instance, detecting buildings with sample sizes of 3 by 3 meters may be inappropriate whereas the same sample size may be appropriate for detecting small gullies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">sdg</span><span class="o">.</span><span class="n">regular_grid</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Created </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s1"> samples&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Created 323 samples
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>POLYGON ((806795 1375599.99, 806795 1380599.99...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>POLYGON ((811957.2222222222 1375599.99, 811957...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>POLYGON ((817119.4444444445 1375599.99, 817119...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>POLYGON ((822281.6666666666 1375599.99, 822281...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>POLYGON ((827443.8888888889 1375599.99, 827443...</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/ks-preprocess-dem_12_2.png" src="../../_images/ks-preprocess-dem_12_2.png" />
</div>
</div>
<p>Similarly, you could create a dataframe with random samples. In this case, you will need to specify the number of samples in addition to the width and height dimensions of each sample in the native resolution of the SDG source raster. For example, here we created 323 samples as in the regular grid with equal dimensions of 5000 feet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_rand</span> <span class="o">=</span> <span class="n">sdg</span><span class="o">.</span><span class="n">random_grid</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">323</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Created </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_rand</span><span class="p">)</span><span class="si">}</span><span class="s1"> samples&#39;</span><span class="p">)</span>
<span class="n">df_rand</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Created 323 samples
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff10e4f2128&gt;
</pre></div>
</div>
<img alt="../../_images/ks-preprocess-dem_14_2.png" src="../../_images/ks-preprocess-dem_14_2.png" />
</div>
</div>
</div>
<div class="section" id="sample-iterator">
<h3>2.3 Sample Iterator<a class="headerlink" href="#sample-iterator" title="Permalink to this headline">¶</a></h3>
<p>Developers familiar with ImageDataGenerator may be familiar with the <em>flow_from_dataframe</em> method that returns an iterator that reads images from the file system based on the path contained in the dataframe. The SDG <em>flow_from_dataframe</em> method performs similarly returning an iterator that performs the following steps:</p>
<ul class="simple">
<li><p>Extract sample data from raster source, reprojecting if necessary</p></li>
<li><p>Resample data to match model input size</p></li>
<li><p>Invoke any requested callback functions on each sample</p></li>
<li><p>Stack samples into desired batch sizes</p></li>
</ul>
<p>The most important task of the <em>flow_from_dataframe</em> generator is to return arrays that match the input size expected by the model. The iterator always returns a NumPy array of shape <em>(batch_size, height, width, layers)</em>. <em>Batch_size, height,</em> and <em>width</em> are parameters passed to the <em>flow_from_dataframe</em> method and should be self-explanatory. The <em>layers</em> may be indexes (also known as bands) read from the source raster, data created using the SDG callback mechanism, or a combination of the two.</p>
<p>The SDG callback mechanism enables on-the-fly data transformation or augmentation of each sample. A callback can be any function that accepts a NumPy array of shape (1, width, height, n) and returns a NumPy array of shape (1, width, height, m) so the callback may produce new layers. Callbacks are invoked as a pipeline with the results of the earlier callbacks being passed to the subsequent callback. The final callback should always produce an array that matches the model input size.</p>
</div>
</div>
<div class="section" id="a-practical-example-preprocessing-digital-elevation-models-dem">
<h2>3. A Practical Example: Preprocessing Digital Elevation Models (DEM)<a class="headerlink" href="#a-practical-example-preprocessing-digital-elevation-models-dem" title="Permalink to this headline">¶</a></h2>
<p>We will start with a simple example of preparing Digital Elevation Models (DEM) for a landscape morphological classification using a deep learning model. Here we have two input rasters (1) an elevation raster that we want to segment and (2) a label raster that identifies the locations grass waterways, which are commonly found surface hydrology features in agriculture fields. The model produces a binary classification of positions on the landscape that are associated with waterways.</p>
<p>The DEM raster, below, shows the height of every pixel over the Lake Bloomington Watershed area in central Illinois, where the dark pixels are regions with lower elevation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dem_path</span> <span class="o">=</span> <span class="s1">&#39;./data/raster.tiff&#39;</span>
<span class="n">dem</span> <span class="o">=</span> <span class="n">SpatialDataGenerator</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">dem_path</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">dem</span><span class="o">.</span><span class="n">src</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ks-preprocess-dem_19_0.png" src="../../_images/ks-preprocess-dem_19_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff10b2cbda0&gt;
</pre></div>
</div>
</div>
</div>
<p>The label is a binary raster where light color pixels indicate the locations of the feature of interest, in this case, grass waterways. You should notice that the features are concentrated within the boundaries of the Lake Bloomington Watershed. Areas outside of the watershed were not manually labeled, therefore we can not use them to train the model, and these areas must be excluded from the training and evaluation samples set. It should be also noticed that the geographic projection and spatial resolution of DEM and label rasters are different, but both rasters’ units are in feet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_path</span> <span class="o">=</span> <span class="s1">&#39;./data/label.tiff&#39;</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">SpatialDataGenerator</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">label_path</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">src</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ks-preprocess-dem_21_0.png" src="../../_images/ks-preprocess-dem_21_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff10b1037f0&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="managing-sample-space">
<h3>3.1 Managing sample space<a class="headerlink" href="#managing-sample-space" title="Permalink to this headline">¶</a></h3>
<p>One of the advantages of using a GeoDataFrame to store the boundaries of the samples is easy filtering and selecting samples to feed to the deep learning model. You can select a subset of samples either by applying a spatial selection criterion (intersection, within, etc.) with an external vector file or by applying a database query on the sample attributes columns. We will discuss how to create sample attributes columns later, but let us start with selecting samples based on spatial relationships.</p>
<div class="section" id="selecting-samples-within-an-area-of-interest">
<h4>Selecting samples within an area of interest<a class="headerlink" href="#selecting-samples-within-an-area-of-interest" title="Permalink to this headline">¶</a></h4>
<p>Selecting samples based on spatial relationships is useful in the case that the study area has an irregular boundary, or as we mentioned earlier, some areas might have not been included in the manual labeling. Keras Spatial inherited the spatial queries from geopandas, therefore Keras Spatial supports any complicated spatial selection criteria on the samples objects.</p>
<p>We will use the Lake Bloomington watershed as a mask and select only the samples that intersect the watershed boundaries. Notice that you could use a more complicated spatial relationship as a selection criterion, such as selecting samples that fall within, touch, or do not intersect with the boundaries of a vector object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">watershed_path</span> <span class="o">=</span> <span class="s1">&#39;./data/watershed.geojson&#39;</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">watershed_path</span><span class="p">)</span>
<span class="n">mask</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff10b0e40f0&gt;
</pre></div>
</div>
<img alt="../../_images/ks-preprocess-dem_26_1.png" src="../../_images/ks-preprocess-dem_26_1.png" />
</div>
</div>
<p>Here we select all the samples that intersects our watershed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">intersects</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">unary_union</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">samples</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff10b089c50&gt;
</pre></div>
</div>
<img alt="../../_images/ks-preprocess-dem_28_1.png" src="../../_images/ks-preprocess-dem_28_1.png" />
</div>
</div>
</div>
<div class="section" id="calculating-attributes-for-each-sample">
<h4>Calculating attributes for each sample<a class="headerlink" href="#calculating-attributes-for-each-sample" title="Permalink to this headline">¶</a></h4>
<p>Upon creating a GeoDataFrame for samples, it will contain a single column with the bounding box (geometry) of each sample. A powerful concept in Keras Spatial is setting selection criteria based on sample attributes. This capability comes handy when quantifying class imbalance in training samples, or the geographic bias of samples towards an area with specific attributes, such as specific soil type, average elevation, etc. Once these attributes are added to your GeoDataFrame, selecting samples will be a matter of applying conditional query based on column values as in slicing any DataFrame. The question is how to add the samples attributes to the samples GeoDataFrame?</p>
<p>An easy way to solve this problem is to use the SpatialDataGenerator’s iterator to extract samples from the source raster, calculate the attribute for each sample, and store it as a column in the GeoDataFrame. In the following example, the count of labels pixels will be extracted from the label raster and added as a second column named features in the samples’ GeoDataFrame. We defined a batch size of one to guarantee a one to one correspondence with every single sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define label raster as a source raster </span>
<span class="n">label_path</span> <span class="o">=</span> <span class="s1">&#39;./data/label.tiff&#39;</span>  
<span class="n">lsdg</span> <span class="o">=</span> <span class="n">SpatialDataGenerator</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">label_path</span><span class="p">)</span>

<span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span>
<span class="n">samples</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">arr</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span> <span class="p">))</span> 
                    <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">lsdg</span><span class="o">.</span><span class="n">flow_from_dataframe</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

<span class="n">samples</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;features&#39;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">samples</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>features</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>POLYGON ((879066.1111111111 1375599.99, 879066...</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>15</th>
      <td>POLYGON ((884228.3333333334 1375599.99, 884228...</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>16</th>
      <td>POLYGON ((889390.5555555555 1375599.99, 889390...</td>
      <td>46.056988</td>
    </tr>
    <tr>
      <th>17</th>
      <td>POLYGON ((894552.7777777778 1375599.99, 894552...</td>
      <td>642.023926</td>
    </tr>
    <tr>
      <th>18</th>
      <td>POLYGON ((899715 1375599.99, 899715 1380599.99...</td>
      <td>218.907867</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/ks-preprocess-dem_31_1.png" src="../../_images/ks-preprocess-dem_31_1.png" />
</div>
</div>
<p>The same process could be repeated to add more attributes from other raster files. In the following cell, we calculate the average elevation of each sample. Remarkably, we can add attributes from vector layers as well. For example, a land cover layer could be used to estimate the dominant land cover type of each sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dem_path</span> <span class="o">=</span> <span class="s1">&#39;./data/raster.tiff&#39;</span>
<span class="n">rsdg</span> <span class="o">=</span> <span class="n">SpatialDataGenerator</span><span class="p">(</span><span class="n">dem_path</span><span class="p">)</span>

<span class="n">samples</span><span class="p">[</span><span class="s1">&#39;elevation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">arr</span><span class="p">))</span> <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">rsdg</span><span class="o">.</span><span class="n">flow_from_dataframe</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">samples</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;elevation&#39;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff10b2bc978&gt;
</pre></div>
</div>
<img alt="../../_images/ks-preprocess-dem_33_1.png" src="../../_images/ks-preprocess-dem_33_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="estimating-global-statistics">
<h3>3.2 Estimating global statistics<a class="headerlink" href="#estimating-global-statistics" title="Permalink to this headline">¶</a></h3>
<p>One of the major challenges that you could face when using data generators is estimating global statistics for the entire samples set. For example, in the case that you want to normalize each sample using the global maximum and minimum of the entire data set. This process is difficult because of the piecewise strategy of the data generator to load a batch of samples at a time. Although this strategy uses memory efficiently, it makes the retrieval of global statistics difficult.</p>
<p>We adopted a two-step solution to solve this problem with Keras Spatial. In the first step, we estimate the local statistical attributes for each sample. In the second step, the global attribute is passed as a parameter to the SDG callback function.</p>
<p>In the following example, we estimate the global maximum and minimum elevation by first adding two columns with the maximum and minimum elevation for each sample (local statistics) as we demonstrated before. Once the minimum and maximum columns are added to the dataframe, we can estimate the global maximum and minimum directly from the dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;maxelv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">arr</span><span class="p">))</span> <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">rsdg</span><span class="o">.</span><span class="n">flow_from_dataframe</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">samples</span><span class="p">[</span><span class="s1">&#39;minelv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">arr</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)))</span> <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">rsdg</span><span class="o">.</span><span class="n">flow_from_dataframe</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">maxelv</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">samples</span><span class="o">.</span><span class="n">minelv</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>912.4614868164062 724.9473266601562
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-normalization-using-a-callback-function">
<h3>3.3 Sample normalization using a callback function<a class="headerlink" href="#sample-normalization-using-a-callback-function" title="Permalink to this headline">¶</a></h3>
<p>Here we define a normalization function and use it as a callback. The first sample is plotted for demonstration purposes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">gmin</span><span class="p">,</span> <span class="n">gmax</span><span class="p">):</span>
    <span class="k">return</span>  <span class="p">(</span><span class="n">arr</span> <span class="o">-</span> <span class="n">gmin</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">gmax</span> <span class="o">-</span> <span class="n">gmin</span><span class="p">)</span>
    
<span class="n">sdg</span><span class="o">.</span><span class="n">add_preprocess_callback</span><span class="p">(</span><span class="s1">&#39;elvnorm&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">minelv</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">samples</span><span class="o">.</span><span class="n">maxelv</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">sdg</span><span class="o">.</span><span class="n">flow_from_dataframe</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">arr</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span>

<span class="n">imgplot</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x7ff1095a7278&gt;
</pre></div>
</div>
<img alt="../../_images/ks-preprocess-dem_39_1.png" src="../../_images/ks-preprocess-dem_39_1.png" />
</div>
</div>
</div>
<div class="section" id="feeding-data-directly-to-train-a-deep-learning-model">
<h3>3.4 Feeding data directly to train a deep learning model<a class="headerlink" href="#feeding-data-directly-to-train-a-deep-learning-model" title="Permalink to this headline">¶</a></h3>
<p>After the sample data frame is filtered and all the relevant samples are selected, then it can be used to feed data in a stepwise fashion to the deep learning model. Our final challenge is to provide a tuple containing our label and source data. We use Python’s zip function to create a new iterator that is passed to the TensorFlow model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># example of Feeding samples to a DL model </span>
<span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span>
<span class="n">train_gen</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">flow_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">),</span> <span class="n">dem</span><span class="o">.</span><span class="n">flow_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>4. Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>We introduced Keras Spatial that provides a preprocessing module tailored for remote sensing and geospatial data. Keras Spatial reduces the friction in handling geospatial data by providing loosely coupled preprocessing capabilities to retrieve and transform data on-the-fly before feeding them to deep learning models. Through this notebook, you learned the advantages of using Keras Spatial over more traditional Ad-hoc pipelines, particularly in (1) preparing your samples set in a reproducible way and (2) controlling the sample space and hence avoiding issues such as bias and class imbalance during training. Keras Spatial could also contribute to solving the Geo-AI model bias problem, by providing means to quantify the samples’ statistical distribution and estimate the degree of concordance between the statistical distribution of training and prediction datasets to ensure the quality of prediction. Please refer to <a class="reference external" href="https://dl.acm.org/doi/10.1145/3356471.3365240">(Soliman and Terstriep, 2019)</a> for more information about Keras Spatial.</p>
</div>
<div class="section" id="acknowledgment">
<h2>Acknowledgment<a class="headerlink" href="#acknowledgment" title="Permalink to this headline">¶</a></h2>
<p>This research is based in part upon work supported by the Illinois Natural Resources Conservation Service, Illinois State Geological Survey, and the Illinois State Water Survey.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ec2020/ec20_soliman_etal"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">EC2020 examples</a>
    <a class='right-next' id="next-link" href="../ec20_banihirwe_etal/intake-pangeo-catalog.html" title="next page">Intake / Pangeo Catalog: Making It Easier To Consume Earth’s Climate and Weather Data</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By EarthCube Office<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>